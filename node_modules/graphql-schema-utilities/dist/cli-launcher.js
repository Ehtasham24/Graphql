#!/usr/bin/env node
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const program = require("commander");
const fs = require("fs");
const path = require("path");
const cli = require("./cli");
const logger_1 = require("./logger");
const printers_1 = require("./printers");
const packageJson = require('../package.json');
program
    .version(packageJson.version)
    .usage(`[options] (<glob.graphql>)`)
    .option('-o, --output [pattern]', 'The file path where the merged schema will be outputted to.')
    .option('-s, --schema [pattern]', 'Use a glob path that would define all of your schema files to merge them into a valid schema.', '')
    .option('-r, --rules [pattern]', 'The file path for your custom rules to validate your operations, and your merged schema.', '')
    .option('-p, --operations [pattern]', 'Use a glob that that contains your graphql operation files to test against the merged schema file.', '')
    .option('-q, --quiet', 'Run in quite mode, suppressing all logs except errors.', false)
    .option('-d, --includeDirectives', 'By default will NOT merge the directives, unless you added this flag.', false)
    .parse(process.argv);
if (!program.schema) {
    program.outputHelp();
}
else {
    cli.mergeGQLSchemas(program.schema)
        .then((schema) => {
        let data = '';
        if (program.includeDirectives) {
            data = (0, printers_1.printSchemaWithDirectives)(schema);
        }
        else {
            data = (0, printers_1.printSchemaDefault)(schema);
        }
        if (schema.getQueryType().toString() === 'Query' && (!schema.getMutationType()
            || schema.getMutationType().toString() === 'Mutation')
            && (!schema.getSubscriptionType()
                || schema.getSubscriptionType().toString() === 'Subscription')) {
            const typeDefs = `schema { \n  query: Query ${schema.getMutationType()
                ? '\n  mutation: Mutation' : ''} ${schema.getSubscriptionType()
                ? '\n  subscription: Subscription' : ''}  \n}\n\n`;
            data = typeDefs + data;
        }
        if (!program.quiet) {
            process.stdout.write(data);
        }
        if (program.output) {
            ensureDirectoryExistence(program.output);
            fs.writeFile(program.output, data, (err) => {
                if (err) {
                    logger_1.consoleLogger.error('Error while copying the merged schema into the file. ', program.output, err);
                    process.exit(1);
                }
                else {
                    logger_1.consoleLogger.log('Successfully written merged schema into a file.');
                }
            });
        }
        if (program.operations) {
            if (!program.rules) {
                cli.validateOperations(program.operations, schema).catch((error) => {
                    logger_1.consoleLogger.error('Operation files are not valid!');
                    process.exit(1);
                });
            }
            else {
                try {
                    const setOfRules = require(`${program.rules}`);
                    cli.validateOperations(program.operations, schema, setOfRules.specifiedRules).catch((error) => {
                        logger_1.consoleLogger.error('Operation files are not valid!\n');
                        process.exit(1);
                    });
                }
                catch (err) {
                    logger_1.consoleLogger.error(`Could not read ${(program.rules)} for the custom validation rules. Exiting...`, err);
                    process.exit(1);
                }
            }
        }
    })
        .catch((err) => {
        logger_1.consoleLogger.error('Could not merge Schema files!\n', err);
        process.exit(1);
    });
}
function ensureDirectoryExistence(filePath) {
    const dirname = path.dirname(filePath);
    if (fs.existsSync(dirname)) {
        return true;
    }
    ensureDirectoryExistence(dirname);
    fs.mkdirSync(dirname);
}
//# sourceMappingURL=cli-launcher.js.map